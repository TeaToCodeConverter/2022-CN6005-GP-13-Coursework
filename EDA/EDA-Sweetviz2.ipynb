{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## impports very important libraries run this cell first (TeaToCodeConverter)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import sweetviz as sv\n",
    "#import tensorflow as tf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imports\n",
    "\n",
    "importing unlabeled  data as U1\n",
    "importing labeled data as L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = pd.read_csv(\"../DataSets/Breast cancer dataset/breast-cancer-wisconsin.data\",header=None,index_col=0)\n",
    "l1 = pd.read_csv(\"../DataSets/Breast cancer dataset/breast-cancer-wisconsin.data\",header=None, names=['id','clump_thickness','uniformity_of_cell_size','uniformity_of_cell_shape','marginal_adhesion','single_epithelial_cell_size','bare_nuclei','bland_chromatin','normal_nucleoli','mitoses','class1'],index_col=0)\n",
    "u1.head()\n",
    "l1.head()\n",
    "#print(u1.head())\n",
    "#print(\"l1\")\n",
    "#print(l1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(pd.to_numeric(l1[\"bare_nuclei\"]))\n",
    "type(l1[\"bare_nuclei\"])\n",
    "#pd.to_numeric(l1[\"bare_nuclei\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up the data\n",
    "l1['class1'].replace({2:0,4:1},inplace=True)\n",
    "l1\n",
    "analysis = sv.analyze(l1)\n",
    "analysis.show_html('EDA-Sweetviz2predrop.html', open_browser=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweetvis summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "x=l1.drop('class1',axis=1)\n",
    "y=l1['class1']\n",
    "x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the dataset\n",
    "\n",
    "analysis = sv.analyze(l1, target_feat='class1')\n",
    "analysis.show_html('EDA-Sweetviz2.html', open_browser=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dislay resuls in the notebook\n",
    "import IPython\n",
    "ip = IPython.display.IFrame(src='EDA-Sweetviz2.html', width=1000, height=600)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using Sklearn to class1ify the class1 data and plot some graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_y = LabelEncoder()\n",
    "l1.class1 = labelencoder_y.fit_transform(l1.class1.values)\n",
    "\n",
    "sns.pairplot(l1, hue='class1')\n",
    "\n",
    "#reencode entire dataframe\n",
    "l1 = l1.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the correlation of the columns\n",
    "l1.corr()\n",
    "\n",
    "#visualize the correlation\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(l1.corr(), annot=True, fmt='.0%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into independent 'X' and dependent 'Y' variables\n",
    "\n",
    "X=l1.drop('class1',axis=1)\n",
    "\n",
    "Y=l1['class1']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without scaling funtion for the models\n",
    "def models(X_train,Y_train):\n",
    "    \n",
    "    #Logistic Regression\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    log = LogisticRegression(random_state = 0)\n",
    "    log.fit(X_train, Y_train)\n",
    "    \n",
    "    #Decision Tree\n",
    "    from sklearn import tree\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    dtc = DecisionTreeClassifier(criterion = 'entropy',random_state=0)\n",
    "    dtcRender = dtc.fit(X_train, Y_train) \n",
    "\n",
    "    \n",
    "    #Random Forest class1ifier\n",
    "    from sklearn.ensemble import RandomForestclass1ifier\n",
    "    forest = RandomForestclass1ifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "    forest.fit(X_train, Y_train)\n",
    "\n",
    "    #print model accuracy on the training data.\n",
    "\n",
    "    print('[0]Logistic Regression Training Accuracy:', log.score(X_train, Y_train))\n",
    "    print('[1]Decision Tree class1ifier Training Accuracy:', dtc.score(X_train, Y_train))\n",
    "    print('[2]Random Forest class1ifier Training Accuracy:', forest.score(X_train, Y_train))\n",
    "\n",
    "    return log, dtc, dtcRender, forest\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all of the models\n",
    "model = models(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model accuracy on test data on confusion matrix for the models\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "for i in model:\n",
    "    print('Model ', i)\n",
    "    cm = confusion_matrix(Y_test, i.predict(X_test))\n",
    "    #TN, FP, FN, TP variables\n",
    "    TP = cm[0][0]\n",
    "    TN = cm[1][1]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "\n",
    "    print(cm)\n",
    "    ## really important to formula it is the accuracy of the model\n",
    "    print('Testing Accuracy = \"{}!\"'.format( (TP + TN) / (TP + TN + FN + FP)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing from other libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import class1ification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for i in range(len(model)):\n",
    "    print('Model ', i)\n",
    "    # Check precision, recall, f1-score\n",
    "    print( class1ification_report(Y_test, model[i].predict(X_test)) )\n",
    "    # Another way to get the models accuracy on the test data\n",
    "    print( accuracy_score(Y_test, model[i].predict(X_test)))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#class1ify the data using the random forest class1ifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model[2].predict(X_test)\n",
    "print(pred.tolist())\n",
    "print()\n",
    "print(Y_test.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the desicion tree\n",
    "from IPython.display import Image\n",
    "from six import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "features = list(l1.columns[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dtcRender)\n",
    "#print(dir(model[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "tree.plot_tree(dtcRender)\n",
    "plot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_report = sv.compare([X_train, 'Train'], [X_test, 'Test'], 'class1')\n",
    "compare_report.show_html('EDA-Sweetviz-Compare2.html', open_browser=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
