{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph viz dosnt work\n",
    "\n",
    "import graphviz\n",
    "from sklearn import tree\n",
    "dot_data = tree.export_graphviz(dtc,out_file=None,\n",
    "feature_names=features,\n",
    "class_names=['0','1'],\n",
    "filled=True, rounded=True,)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"breastcancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into independent 'X' and dependent 'Y' variables\n",
    "\n",
    "X=l1.drop('diagnosis',axis=1)\n",
    "\n",
    "Y=l1['diagnosis']\n",
    "\n",
    "# Splitting the data into training and Validateing sets\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_Validate_split\n",
    "\n",
    "X_train, X_Validate, Y_train, Y_Validate = train_Validate_split(X, Y, Validate_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_Validate = sc.transform(X_Validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without scaling funtion for the models\n",
    "def models(X_train,Y_train):\n",
    "    \n",
    "    #Logistic Regression\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    log = LogisticRegression(random_state = 0)\n",
    "    log.fit(X_train, Y_train)\n",
    "    \n",
    "    #Decision Tree\n",
    "    from sklearn import tree\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    dtc = DecisionTreeClassifier(criterion = 'entropy',random_state=0)\n",
    "    dtcRender = dtc.fit(X_train, Y_train) \n",
    "\n",
    "    \n",
    "    #Random Forest diagnosisifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "    forest.fit(X_train, Y_train)\n",
    "    \n",
    "    # K fold Cross Validation\n",
    "    \n",
    "    # Define the KFold cross validation iterator\n",
    "    kfold = KFold(n_splits=4, shuffle=True, random_state=1)\n",
    "    \n",
    "    # Loop through the folds and fit/evaluate the model\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        model.fit(X[train_index], y[train_index], epochs=10, verbose=0)\n",
    "        scores = model.evaluate(X[test_index], y[test_index], verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    \n",
    "    #print model accuracy on the training data.\n",
    "\n",
    "    print('[0]Logistic Regression Training Accuracy:', log.score(X_train, Y_train))\n",
    "    print('[1]Decision Tree diagnosisifier Training Accuracy:', dtc.score(X_train, Y_train))\n",
    "    print('[2]Random Forest diagnosisifier Training Accuracy:', forest.score(X_train, Y_train))\n",
    "\n",
    "    return log, dtc, dtcRender, forest, kfold\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without scaling funtion for the models\n",
    "def models(X_train,Y_train):\n",
    "    \n",
    "    #Logistic Regression\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    log = LogisticRegression(random_state = 0)\n",
    "    log.fit(X_train, Y_train)\n",
    "    \n",
    "    #Decision Tree\n",
    "    from sklearn import tree\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    dtc = DecisionTreeClassifier(criterion = 'entropy',random_state=0)\n",
    "    dtcRender = dtc.fit(X_train, Y_train) \n",
    "\n",
    "    \n",
    "    #Random Forest diagnosisifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "    forest.fit(X_train, Y_train)\n",
    "    \n",
    "    # K fold Cross Validation\n",
    "    \n",
    "    # Define the KFold cross validation iterator\n",
    "    kfold = KFold(n_splits=4, shuffle=True, random_state=1)\n",
    "    \n",
    "    # Loop through the folds and fit/evaluate the model\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        model.fit(X[train_index], y[train_index], epochs=10, verbose=0)\n",
    "        scores = model.evaluate(X[test_index], y[test_index], verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    \n",
    "    #print model accuracy on the training data.\n",
    "\n",
    "    print('[0]Logistic Regression Training Accuracy:', log.score(X_train, Y_train))\n",
    "    print('[1]Decision Tree diagnosisifier Training Accuracy:', dtc.score(X_train, Y_train))\n",
    "    print('[2]Random Forest diagnosisifier Training Accuracy:', forest.score(X_train, Y_train))\n",
    "\n",
    "    return log, dtc, dtcRender, forest, kfold\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the KFold cross validation iterator\n",
    "kfold = KFold(n_splits=4, shuffle=True, random_state=1)\n",
    "\n",
    "# Loop through the folds and fit/evaluate the model\n",
    "for train_index, test_index in kfold.split(X):\n",
    "  model.fit(X[train_index], y[train_index], epochs=10, verbose=0)\n",
    "  scores = model.evaluate(X[test_index], y[test_index], verbose=0)\n",
    "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
